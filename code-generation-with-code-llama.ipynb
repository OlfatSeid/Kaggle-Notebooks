{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4659,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":3449,"modelId":1281}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T11:32:32.162195Z","iopub.execute_input":"2024-12-02T11:32:32.162553Z","iopub.status.idle":"2024-12-02T11:32:36.274975Z","shell.execute_reply.started":"2024-12-02T11:32:32.162520Z","shell.execute_reply":"2024-12-02T11:32:36.274276Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### Loading the model and tokenizer","metadata":{}},{"cell_type":"code","source":"model_name = \"/kaggle/input/codellama/pytorch/13b-python-hf/1\" \ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T11:32:36.276357Z","iopub.execute_input":"2024-12-02T11:32:36.276712Z","iopub.status.idle":"2024-12-02T11:33:34.651370Z","shell.execute_reply.started":"2024-12-02T11:32:36.276685Z","shell.execute_reply":"2024-12-02T11:33:34.650470Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4074eaa053f24b7eb9b3ff1157ec14fc"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"def do_generation(prompt):\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n\n    outputs = model.generate(\n          inputs.input_ids,\n          max_length=500,  \n          temperature=0.7,  \n          top_p=0.9,        # Sampling parameter\n          do_sample=True\n    )\n\n    generated_code = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    output=print( generated_code)\n    return output\n    \n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T11:33:34.653024Z","iopub.execute_input":"2024-12-02T11:33:34.653616Z","iopub.status.idle":"2024-12-02T11:33:34.658467Z","shell.execute_reply.started":"2024-12-02T11:33:34.653573Z","shell.execute_reply":"2024-12-02T11:33:34.657611Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Code in-filling\r\n\r\n- Use Code Llama to fill in partially completed code.","metadata":{}},{"cell_type":"code","source":"prompt = \"\"\"\ndef star_rating(n):\n'''\n  This function returns a rating given the number n,\n  where n is an integers from 1 to 5.\n'''\n\n    if n == 1:\n        rating=\"poor\"\n    <FILL>\n    elif n == 5:\n        rating=\"excellent\"\n\n    return rating\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T11:33:34.660834Z","iopub.execute_input":"2024-12-02T11:33:34.661581Z","iopub.status.idle":"2024-12-02T11:33:34.668815Z","shell.execute_reply.started":"2024-12-02T11:33:34.661551Z","shell.execute_reply":"2024-12-02T11:33:34.667889Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"do_generation(prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T11:33:34.669975Z","iopub.execute_input":"2024-12-02T11:33:34.670791Z","iopub.status.idle":"2024-12-02T11:33:51.156633Z","shell.execute_reply.started":"2024-12-02T11:33:34.670757Z","shell.execute_reply":"2024-12-02T11:33:51.155650Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nStarting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n","output_type":"stream"},{"name":"stdout","text":"\ndef star_rating(n):\n'''\n  This function returns a rating given the number n,\n  where n is an integers from 1 to 5.\n'''\n\n    if n == 1:\n        rating=\"poor\"\n    <FILL>\n    elif n == 5:\n        rating=\"excellent\"\n\n    return rating\n\n\nprint(star_rating(3))\n# Should print 'average'\n\nprint(star_rating(4))\n# Should print 'good'\n\nprint(star_rating(1))\n# Should print 'poor'\n\nprint(star_rating(5))\n# Should print 'excellent'\n\nprint(star_rating(2))\n# Should print 'average'\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Compare the runtimes of the two functions","metadata":{}},{"cell_type":"code","source":"prompt_2 = f\"\"\"\nProvide sample code that calculates the runtime \\\nof a Python function call.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T11:33:51.157927Z","iopub.execute_input":"2024-12-02T11:33:51.158964Z","iopub.status.idle":"2024-12-02T11:33:51.163037Z","shell.execute_reply.started":"2024-12-02T11:33:51.158916Z","shell.execute_reply":"2024-12-02T11:33:51.162096Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"do_generation(prompt_2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T11:33:51.164083Z","iopub.execute_input":"2024-12-02T11:33:51.164699Z","iopub.status.idle":"2024-12-02T11:34:07.748599Z","shell.execute_reply.started":"2024-12-02T11:33:51.164669Z","shell.execute_reply":"2024-12-02T11:34:07.747674Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nProvide sample code that calculates the runtime of a Python function call.\n\n\"\"\"\n\ndef time_this(function):\n    def wrapper(*args, **kwargs):\n        import time\n        t1 = time.time()\n        result = function(*args, **kwargs)\n        t2 = time.time()\n        print(f'Elapsed time: {(t2 - t1):.4f} seconds')\n        return result\n    return wrapper\n\n@time_this\ndef sum_of_squares(n):\n    return sum([i**2 for i in range(n)])\n\n\nif __name__ == '__main__':\n    sum_of_squares(10000000)\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Write a Fibonacci number","metadata":{}},{"cell_type":"code","source":"prompt_3 = \"\"\"\nProvide a function that calculates the n-th fibonacci number.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T11:34:07.749872Z","iopub.execute_input":"2024-12-02T11:34:07.750300Z","iopub.status.idle":"2024-12-02T11:34:07.754521Z","shell.execute_reply.started":"2024-12-02T11:34:07.750258Z","shell.execute_reply":"2024-12-02T11:34:07.753690Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"do_generation(prompt_3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T11:34:07.755682Z","iopub.execute_input":"2024-12-02T11:34:07.756035Z","iopub.status.idle":"2024-12-02T11:34:59.973991Z","shell.execute_reply.started":"2024-12-02T11:34:07.755995Z","shell.execute_reply":"2024-12-02T11:34:59.973067Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nProvide a function that calculates the n-th fibonacci number.\n\nExamples:\n\nfib(10) # 55\nfib(1) # 1\nfib(2) # 1\nfib(3) # 2\nfib(4) # 3\nfib(5) # 5\nfib(6) # 8\nfib(7) # 13\nfib(8) # 21\nfib(9) # 34\nfib(10) # 55\nfib(11) # 89\nfib(12) # 144\nfib(13) # 233\nfib(14) # 377\nfib(15) # 610\nfib(16) # 987\nfib(17) # 1597\nfib(18) # 2584\nfib(19) # 4181\nfib(20) # 6765\nfib(21) # 10946\nfib(22) # 17711\nfib(23) # 28657\nfib(24) # 46368\nfib(25) # 75025\nfib(26) # 121393\nfib(27) # 196418\nfib(28) # 317811\nfib(29) # 514229\nfib(30) # 832040\nfib(31) # 1346269\nfib(32) # 2178309\nfib(33) # 3524578\nfib(34) # 5702887\nfib(35) # 9227465\nfib(36) # 14930352\nfib\n","output_type":"stream"}],"execution_count":9}]}