{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\npip install --upgrade torch  torchvision transformers datasets accelerate bitsandbytes peft trl","metadata":{"execution":{"iopub.status.busy":"2024-10-14T18:47:14.094529Z","iopub.execute_input":"2024-10-14T18:47:14.095377Z","iopub.status.idle":"2024-10-14T18:49:55.867220Z","shell.execute_reply.started":"2024-10-14T18:47:14.095324Z","shell.execute_reply":"2024-10-14T18:49:55.865956Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport os\nfrom tqdm import tqdm\nimport bitsandbytes as bnb\nimport torch\nimport torch.nn as nn\nimport transformers\nfrom datasets import Dataset\nfrom peft import LoraConfig, PeftConfig,PeftModel\nfrom trl import SFTTrainer\nfrom sklearn.metrics import (accuracy_score, \n                             classification_report, \n                             confusion_matrix)\n\nfrom trl import setup_chat_format\nfrom transformers import (AutoModelForCausalLM, \n                          AutoTokenizer, \n                          BitsAndBytesConfig, \n                          TrainingArguments, \n                          pipeline, \n                          logging)\n\n\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\n\n# Ensure reproducibility for CUDA (if using GPU)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\nmodel_name = \"/kaggle/input/llama-3.2/transformers/3b-instruct/1\"\nnew_model=\"fine-tuned-llama-3.2-model\"","metadata":{"execution":{"iopub.status.busy":"2024-10-14T18:49:55.869719Z","iopub.execute_input":"2024-10-14T18:49:55.870146Z","iopub.status.idle":"2024-10-14T18:50:17.019238Z","shell.execute_reply.started":"2024-10-14T18:49:55.870085Z","shell.execute_reply":"2024-10-14T18:50:17.018443Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import wandb\n\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nwb_token = user_secrets.get_secret(\"wandb\")\n\nwandb.login(key=wb_token)\nrun = wandb.init(\n    project='Fine-Tuning Llama-3.2-for Sentiment Analysis', \n    job_type=\"training\", \n    anonymous=\"allow\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T18:50:17.020399Z","iopub.execute_input":"2024-10-14T18:50:17.020989Z","iopub.status.idle":"2024-10-14T18:50:23.274551Z","shell.execute_reply.started":"2024-10-14T18:50:17.020953Z","shell.execute_reply":"2024-10-14T18:50:23.273565Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33molfat\u001b[0m (\u001b[33molfat-sayed\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112751955554105, max=1.0‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a92546a50c54bc5b9f638c22c1c447e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241014_185019-kggxvngt</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/olfat-sayed/Fine-Tuning%20Llama-3.2-for%20Sentiment%20Analysis/runs/kggxvngt' target=\"_blank\">volcanic-salad-15</a></strong> to <a href='https://wandb.ai/olfat-sayed/Fine-Tuning%20Llama-3.2-for%20Sentiment%20Analysis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/olfat-sayed/Fine-Tuning%20Llama-3.2-for%20Sentiment%20Analysis' target=\"_blank\">https://wandb.ai/olfat-sayed/Fine-Tuning%20Llama-3.2-for%20Sentiment%20Analysis</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/olfat-sayed/Fine-Tuning%20Llama-3.2-for%20Sentiment%20Analysis/runs/kggxvngt' target=\"_blank\">https://wandb.ai/olfat-sayed/Fine-Tuning%20Llama-3.2-for%20Sentiment%20Analysis/runs/kggxvngt</a>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Loading & processing the dataset <span style=\"font-size:16px;\">üìä‚öôÔ∏è</span>","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/sentiment-analysis-dataset/train.csv\", encoding='latin1')\ndf","metadata":{"execution":{"iopub.status.busy":"2024-10-14T18:50:23.277074Z","iopub.execute_input":"2024-10-14T18:50:23.277433Z","iopub.status.idle":"2024-10-14T18:50:23.503866Z","shell.execute_reply.started":"2024-10-14T18:50:23.277399Z","shell.execute_reply":"2024-10-14T18:50:23.502827Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"           textID                                               text  \\\n0      cb774db0d1                I`d have responded, if I were going   \n1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n2      088c60f138                          my boss is bullying me...   \n3      9642c003ef                     what interview! leave me alone   \n4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n...           ...                                                ...   \n27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n27479  ed167662a5                         But it was worth it  ****.   \n27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n\n                                           selected_text sentiment  \\\n0                    I`d have responded, if I were going   neutral   \n1                                               Sooo SAD  negative   \n2                                            bullying me  negative   \n3                                         leave me alone  negative   \n4                                          Sons of ****,  negative   \n...                                                  ...       ...   \n27476                                             d lost  negative   \n27477                                      , don`t force  negative   \n27478                          Yay good for both of you.  positive   \n27479                         But it was worth it  ****.  positive   \n27480  All this flirting going on - The ATG smiles. Y...   neutral   \n\n      Time of Tweet Age of User      Country  Population -2020  \\\n0           morning        0-20  Afghanistan          38928346   \n1              noon       21-30      Albania           2877797   \n2             night       31-45      Algeria          43851044   \n3           morning       46-60      Andorra             77265   \n4              noon       60-70       Angola          32866272   \n...             ...         ...          ...               ...   \n27476         night       31-45        Ghana          31072940   \n27477       morning       46-60       Greece          10423054   \n27478          noon       60-70      Grenada            112523   \n27479         night      70-100    Guatemala          17915568   \n27480       morning        0-20       Guinea          13132795   \n\n       Land Area (Km¬≤)  Density (P/Km¬≤)  \n0             652860.0               60  \n1              27400.0              105  \n2            2381740.0               18  \n3                470.0              164  \n4            1246700.0               26  \n...                ...              ...  \n27476         227540.0              137  \n27477         128900.0               81  \n27478            340.0              331  \n27479         107160.0              167  \n27480         246000.0               53  \n\n[27481 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n      <th>Time of Tweet</th>\n      <th>Age of User</th>\n      <th>Country</th>\n      <th>Population -2020</th>\n      <th>Land Area (Km¬≤)</th>\n      <th>Density (P/Km¬≤)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>morning</td>\n      <td>0-20</td>\n      <td>Afghanistan</td>\n      <td>38928346</td>\n      <td>652860.0</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n      <td>noon</td>\n      <td>21-30</td>\n      <td>Albania</td>\n      <td>2877797</td>\n      <td>27400.0</td>\n      <td>105</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n      <td>night</td>\n      <td>31-45</td>\n      <td>Algeria</td>\n      <td>43851044</td>\n      <td>2381740.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n      <td>morning</td>\n      <td>46-60</td>\n      <td>Andorra</td>\n      <td>77265</td>\n      <td>470.0</td>\n      <td>164</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n      <td>noon</td>\n      <td>60-70</td>\n      <td>Angola</td>\n      <td>32866272</td>\n      <td>1246700.0</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27476</th>\n      <td>4eac33d1c0</td>\n      <td>wish we could come see u on Denver  husband l...</td>\n      <td>d lost</td>\n      <td>negative</td>\n      <td>night</td>\n      <td>31-45</td>\n      <td>Ghana</td>\n      <td>31072940</td>\n      <td>227540.0</td>\n      <td>137</td>\n    </tr>\n    <tr>\n      <th>27477</th>\n      <td>4f4c4fc327</td>\n      <td>I`ve wondered about rake to.  The client has ...</td>\n      <td>, don`t force</td>\n      <td>negative</td>\n      <td>morning</td>\n      <td>46-60</td>\n      <td>Greece</td>\n      <td>10423054</td>\n      <td>128900.0</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>27478</th>\n      <td>f67aae2310</td>\n      <td>Yay good for both of you. Enjoy the break - y...</td>\n      <td>Yay good for both of you.</td>\n      <td>positive</td>\n      <td>noon</td>\n      <td>60-70</td>\n      <td>Grenada</td>\n      <td>112523</td>\n      <td>340.0</td>\n      <td>331</td>\n    </tr>\n    <tr>\n      <th>27479</th>\n      <td>ed167662a5</td>\n      <td>But it was worth it  ****.</td>\n      <td>But it was worth it  ****.</td>\n      <td>positive</td>\n      <td>night</td>\n      <td>70-100</td>\n      <td>Guatemala</td>\n      <td>17915568</td>\n      <td>107160.0</td>\n      <td>167</td>\n    </tr>\n    <tr>\n      <th>27480</th>\n      <td>6f7127d9d7</td>\n      <td>All this flirting going on - The ATG smiles...</td>\n      <td>All this flirting going on - The ATG smiles. Y...</td>\n      <td>neutral</td>\n      <td>morning</td>\n      <td>0-20</td>\n      <td>Guinea</td>\n      <td>13132795</td>\n      <td>246000.0</td>\n      <td>53</td>\n    </tr>\n  </tbody>\n</table>\n<p>27481 rows √ó 10 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.isnull().value_counts(),df.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-14T18:50:23.505079Z","iopub.execute_input":"2024-10-14T18:50:23.505757Z","iopub.status.idle":"2024-10-14T18:50:24.406810Z","shell.execute_reply.started":"2024-10-14T18:50:23.505721Z","shell.execute_reply":"2024-10-14T18:50:24.405846Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(textID  text   selected_text  sentiment  Time of Tweet  Age of User  Country  Population -2020  Land Area (Km¬≤)  Density (P/Km¬≤)\n False   False  False          False      False          False        False    False             False            False              27480\n         True   True           False      False          False        False    False             False            False                  1\n Name: count, dtype: int64,\n (27481, 10))"},"metadata":{}}]},{"cell_type":"code","source":"df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T18:50:24.407842Z","iopub.execute_input":"2024-10-14T18:50:24.408163Z","iopub.status.idle":"2024-10-14T18:50:24.435135Z","shell.execute_reply.started":"2024-10-14T18:50:24.408130Z","shell.execute_reply":"2024-10-14T18:50:24.434298Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df['sentiment'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-10-14T18:50:24.436137Z","iopub.execute_input":"2024-10-14T18:50:24.436398Z","iopub.status.idle":"2024-10-14T18:50:24.447436Z","shell.execute_reply.started":"2024-10-14T18:50:24.436369Z","shell.execute_reply":"2024-10-14T18:50:24.446452Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"array(['neutral', 'negative', 'positive'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"df = df.sample(frac=1, random_state=42).reset_index(drop=True).head(3000)\ntrain_size = 0.8\neval_size = 0.1\n\n\ntrain_end = int(train_size * len(df))\neval_end = train_end + int(eval_size * len(df))\n\n\nX_train = df[:train_end]\nX_eval = df[train_end:eval_end]\nX_test = df[eval_end:]\n\ndef generate_prompt(data_point):\n    return f\"\"\"\n            Classify the text into positive, negative,nuetral, and return the answer as the corresponding sentiment-analysis disorder label.\ncontext: {data_point[\"text\"]}\nlabel: {data_point[\"sentiment\"]}\"\"\".strip()\n\ndef generate_test_prompt(data_point):\n    return f\"\"\"\n            Classify the text into positive, negative,nuetral,and return the answer as the corresponding sentiment-analysis disorder label.\ncontext: {data_point[\"text\"]}\nlabel: \"\"\".strip()\n\nX_train.loc[:,'text'] = X_train.apply(generate_prompt, axis=1)\nX_eval.loc[:,'text'] = X_eval.apply(generate_prompt, axis=1)\n\ny_true = X_test.loc[:,'sentiment']\nX_test = pd.DataFrame(X_test.apply(generate_test_prompt, axis=1), columns=[\"context\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-14T18:50:24.448552Z","iopub.execute_input":"2024-10-14T18:50:24.448810Z","iopub.status.idle":"2024-10-14T18:50:24.519192Z","shell.execute_reply.started":"2024-10-14T18:50:24.448781Z","shell.execute_reply":"2024-10-14T18:50:24.518277Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Convert to datasets\ntrain_data = Dataset.from_pandas(X_train[[\"text\"]])\neval_data = Dataset.from_pandas(X_eval[[\"text\"]])","metadata":{"execution":{"iopub.status.busy":"2024-10-14T18:50:24.520513Z","iopub.execute_input":"2024-10-14T18:50:24.520808Z","iopub.status.idle":"2024-10-14T18:50:24.579322Z","shell.execute_reply.started":"2024-10-14T18:50:24.520778Z","shell.execute_reply":"2024-10-14T18:50:24.578401Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_data['text'][3]","metadata":{"execution":{"iopub.status.busy":"2024-10-14T18:50:24.583430Z","iopub.execute_input":"2024-10-14T18:50:24.584221Z","iopub.status.idle":"2024-10-14T18:50:24.601918Z","shell.execute_reply.started":"2024-10-14T18:50:24.584175Z","shell.execute_reply":"2024-10-14T18:50:24.600991Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'Classify the text into positive, negative,nuetral, and return the answer as the corresponding sentiment-analysis disorder label.\\ncontext:  congrats hey\\nlabel: positive'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Loading the model and tokenizer ü¶ô3.2","metadata":{}},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=False,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=\"float16\",\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map=\"auto\",\n    torch_dtype=\"float16\",\n    quantization_config=bnb_config, \n)\n\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ntokenizer.pad_token_id = tokenizer.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2024-10-14T18:50:24.603278Z","iopub.execute_input":"2024-10-14T18:50:24.603670Z","iopub.status.idle":"2024-10-14T18:51:00.422649Z","shell.execute_reply.started":"2024-10-14T18:50:24.603628Z","shell.execute_reply":"2024-10-14T18:51:00.421860Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a67fa437fde43fe840e280b123f84c0"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Test the Base Model  <span style=\"font-size:16px;\">üìà</span>","metadata":{}},{"cell_type":"code","source":"def predict(test, model, tokenizer):\n    y_pred = []\n    categories = [\"positive\", \"negative\", \"nuetral\"]\n    \n    for i in tqdm(range(len(test))):\n        prompt = test.iloc[i][\"context\"]\n        pipe = pipeline(task=\"text-generation\", \n                        model=model, \n                        tokenizer=tokenizer, \n                        max_new_tokens=2, \n                        temperature=0.1)\n        \n        result = pipe(prompt)\n        answer = result[0]['generated_text'].split(\"label:\")[-1].strip()\n        \n    \n        for category in categories:\n            if category.lower() in answer.lower():\n                y_pred.append(category)\n                break\n        else:\n            y_pred.append(\"none\")\n    \n    return y_pred\n\ny_pred = predict(X_test, model, tokenizer)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-14T18:51:00.423766Z","iopub.execute_input":"2024-10-14T18:51:00.424078Z","iopub.status.idle":"2024-10-14T18:51:46.933875Z","shell.execute_reply.started":"2024-10-14T18:51:00.424044Z","shell.execute_reply":"2024-10-14T18:51:46.932954Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"  0%|          | 0/300 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:46<00:00,  6.45it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate(y_true, y_pred):\n    labels = [\"positive\", \"negative\", \"nuetral\"]\n    mapping = {label: idx for idx, label in enumerate(labels)}\n    \n    def map_func(x):\n        return mapping.get(x, -1)  # Map to -1 if not found, but should not occur with correct data\n    \n    y_true_mapped = np.vectorize(map_func)(y_true)\n    y_pred_mapped = np.vectorize(map_func)(y_pred)\n    \n  \n    accuracy = accuracy_score(y_true=y_true_mapped, y_pred=y_pred_mapped)\n    print(f'Accuracy: {accuracy:.3f}')\n    \n\n    unique_labels = set(y_true_mapped)       # Get unique labels\n    \n    for label in unique_labels:\n        label_indices = [i for i in range(len(y_true_mapped)) if y_true_mapped[i] == label]\n        label_y_true = [y_true_mapped[i] for i in label_indices]\n        label_y_pred = [y_pred_mapped[i] for i in label_indices]\n        label_accuracy = accuracy_score(label_y_true, label_y_pred)\n        print(f'Accuracy for label {labels[label]}: {label_accuracy:.3f}')\n        \n    \n    class_report = classification_report(y_true=y_true_mapped, y_pred=y_pred_mapped, target_names=labels, labels=list(range(len(labels))))\n    print('\\nClassification Report:')\n    print(class_report)\n    \n   \n    conf_matrix = confusion_matrix(y_true=y_true_mapped, y_pred=y_pred_mapped, labels=list(range(len(labels))))\n    print('\\nConfusion Matrix:')\n    print(conf_matrix)\n\nevaluate(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T18:51:46.935285Z","iopub.execute_input":"2024-10-14T18:51:46.935940Z","iopub.status.idle":"2024-10-14T18:51:46.970499Z","shell.execute_reply.started":"2024-10-14T18:51:46.935890Z","shell.execute_reply":"2024-10-14T18:51:46.969653Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Accuracy: 0.587\nAccuracy for label positive: 0.695\nAccuracy for label negative: 0.411\nAccuracy for label nuetral: 0.641\n\nClassification Report:\n              precision    recall  f1-score   support\n\n    positive       0.52      0.70      0.59        82\n    negative       0.77      0.41      0.54        90\n     nuetral       0.00      0.00      0.00         0\n\n   micro avg       0.59      0.55      0.57       172\n   macro avg       0.43      0.37      0.38       172\nweighted avg       0.65      0.55      0.56       172\n\n\nConfusion Matrix:\n[[57  1  0]\n [17 37  0]\n [ 0  0  0]]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Building the Model","metadata":{}},{"cell_type":"code","source":"import bitsandbytes as bnb\n\ndef find_all_linear_names(model):\n    cls = bnb.nn.Linear4bit\n    lora_module_names = set()\n    for name, module in model.named_modules():\n        if isinstance(module, cls):\n            names = name.split('.')\n            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n    if 'lm_head' in lora_module_names:              # needed for 16 bit\n        lora_module_names.remove('lm_head')\n    return list(lora_module_names)\nmodules = find_all_linear_names(model)\nmodules","metadata":{"execution":{"iopub.status.busy":"2024-10-14T18:51:46.971652Z","iopub.execute_input":"2024-10-14T18:51:46.971933Z","iopub.status.idle":"2024-10-14T18:51:46.982158Z","shell.execute_reply.started":"2024-10-14T18:51:46.971902Z","shell.execute_reply":"2024-10-14T18:51:46.981315Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"['q_proj', 'gate_proj', 'up_proj', 'down_proj', 'o_proj', 'k_proj', 'v_proj']"},"metadata":{}}]},{"cell_type":"code","source":"peft_config = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=modules,\n)\n\ntraining_arguments = TrainingArguments(\n    output_dir=new_model,                    \n    num_train_epochs=1,                       \n    per_device_train_batch_size=1,            \n    gradient_accumulation_steps=8,            # number of steps before performing a backward/update pass\n    gradient_checkpointing=True,              #  to save memory\n    optim=\"paged_adamw_32bit\",\n    logging_steps=1,                         \n    learning_rate=2e-4,                       \n    weight_decay=0.001,\n    fp16=True,\n    bf16=False,\n    max_grad_norm=0.3,                        \n    max_steps=-1,\n    warmup_ratio=0.03,                       \n    group_by_length=False,\n    lr_scheduler_type=\"cosine\",            \n    report_to=\"wandb\",                  \n    eval_strategy=\"steps\",              # save checkpoint every epoch\n    eval_steps = 0.1\n)\n\ntrainer = SFTTrainer(\n    model=model,\n    args=training_arguments,\n    train_dataset=train_data,\n    eval_dataset=eval_data,\n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    max_seq_length=512,\n    packing=False,\n    dataset_kwargs={\n    \"add_special_tokens\": False,\n    \"append_concat_token\": False,\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T18:51:46.983281Z","iopub.execute_input":"2024-10-14T18:51:46.983570Z","iopub.status.idle":"2024-10-14T18:51:49.580381Z","shell.execute_reply.started":"2024-10-14T18:51:46.983540Z","shell.execute_reply":"2024-10-14T18:51:49.579612Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length, dataset_kwargs. Will not be supported from version '1.0.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:327: UserWarning: You passed a `dataset_kwargs` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"017a687ebe6c4d64b7cde61f27e75eb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/300 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06e88509eb214821992162e20ec19a91"}},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-14T18:51:49.581382Z","iopub.execute_input":"2024-10-14T18:51:49.581673Z","iopub.status.idle":"2024-10-14T19:13:20.024262Z","shell.execute_reply.started":"2024-10-14T18:51:49.581641Z","shell.execute_reply":"2024-10-14T19:13:20.023424Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [300/300 21:25, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>30</td>\n      <td>1.411900</td>\n      <td>1.741040</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.214300</td>\n      <td>1.696740</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.294900</td>\n      <td>1.673820</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.410400</td>\n      <td>1.667052</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.504600</td>\n      <td>1.659174</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.357500</td>\n      <td>1.653582</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>1.216400</td>\n      <td>1.647382</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>1.519400</td>\n      <td>1.644082</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>1.889500</td>\n      <td>1.642791</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.350200</td>\n      <td>1.642495</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=300, training_loss=1.6407002675533295, metrics={'train_runtime': 1289.8074, 'train_samples_per_second': 1.861, 'train_steps_per_second': 0.233, 'total_flos': 2051320500971520.0, 'train_loss': 1.6407002675533295, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"wandb.finish()\nmodel.config.use_cache = True","metadata":{"execution":{"iopub.status.busy":"2024-10-14T19:13:20.025466Z","iopub.execute_input":"2024-10-14T19:13:20.025778Z","iopub.status.idle":"2024-10-14T19:13:21.755003Z","shell.execute_reply.started":"2024-10-14T19:13:20.025745Z","shell.execute_reply":"2024-10-14T19:13:21.754113Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.032 MB of 0.032 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñà‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ‚ñà‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ‚ñà‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.6425</td></tr><tr><td>eval/runtime</td><td>12.8729</td></tr><tr><td>eval/samples_per_second</td><td>23.305</td></tr><tr><td>eval/steps_per_second</td><td>2.952</td></tr><tr><td>total_flos</td><td>2051320500971520.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>300</td></tr><tr><td>train/grad_norm</td><td>0.24227</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>1.3502</td></tr><tr><td>train_loss</td><td>1.6407</td></tr><tr><td>train_runtime</td><td>1289.8074</td></tr><tr><td>train_samples_per_second</td><td>1.861</td></tr><tr><td>train_steps_per_second</td><td>0.233</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">volcanic-salad-15</strong> at: <a href='https://wandb.ai/olfat-sayed/Fine-Tuning%20Llama-3.2-for%20Sentiment%20Analysis/runs/kggxvngt' target=\"_blank\">https://wandb.ai/olfat-sayed/Fine-Tuning%20Llama-3.2-for%20Sentiment%20Analysis/runs/kggxvngt</a><br/> View project at: <a href='https://wandb.ai/olfat-sayed/Fine-Tuning%20Llama-3.2-for%20Sentiment%20Analysis' target=\"_blank\">https://wandb.ai/olfat-sayed/Fine-Tuning%20Llama-3.2-for%20Sentiment%20Analysis</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241014_185019-kggxvngt/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(new_model)\ntokenizer.save_pretrained(new_model)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T19:13:21.756243Z","iopub.execute_input":"2024-10-14T19:13:21.756544Z","iopub.status.idle":"2024-10-14T19:13:23.051116Z","shell.execute_reply.started":"2024-10-14T19:13:21.756512Z","shell.execute_reply":"2024-10-14T19:13:23.050155Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"('fine-tuned-llama-3.2-model/tokenizer_config.json',\n 'fine-tuned-llama-3.2-model/special_tokens_map.json',\n 'fine-tuned-llama-3.2-model/tokenizer.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Test the Fine-Tuned Model <span style=\"font-size:16px;\">üìâ</span>","metadata":{}},{"cell_type":"code","source":"# Reload tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nbase_model_reload = AutoModelForCausalLM.from_pretrained(\n        model_name,\n        return_dict=True,\n        low_cpu_mem_usage=True,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T19:13:23.052306Z","iopub.execute_input":"2024-10-14T19:13:23.052655Z","iopub.status.idle":"2024-10-14T19:13:31.064878Z","shell.execute_reply.started":"2024-10-14T19:13:23.052623Z","shell.execute_reply":"2024-10-14T19:13:31.064112Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a297ece131448ae8e7583d11463b5a4"}},"metadata":{}}]},{"cell_type":"code","source":"# Merge adapter with base model\ntuned_model = PeftModel.from_pretrained(base_model_reload, new_model)\ntuned_model = tuned_model.merge_and_unload()","metadata":{"execution":{"iopub.status.busy":"2024-10-14T19:13:31.066042Z","iopub.execute_input":"2024-10-14T19:13:31.066390Z","iopub.status.idle":"2024-10-14T19:13:32.996473Z","shell.execute_reply.started":"2024-10-14T19:13:31.066356Z","shell.execute_reply":"2024-10-14T19:13:32.995502Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"tuned_model.eval()\ny_pred = predict(X_test, tuned_model, tokenizer)\nevaluate(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T19:13:32.997742Z","iopub.execute_input":"2024-10-14T19:13:32.998074Z","iopub.status.idle":"2024-10-14T19:14:05.075550Z","shell.execute_reply.started":"2024-10-14T19:13:32.998040Z","shell.execute_reply":"2024-10-14T19:14:05.074676Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"  0%|          | 0/300 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  0%|          | 1/300 [00:00<01:06,  4.53it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  1%|          | 2/300 [00:00<00:46,  6.44it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  1%|          | 3/300 [00:00<00:39,  7.46it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  1%|‚ñè         | 4/300 [00:00<00:36,  8.05it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  2%|‚ñè         | 5/300 [00:00<00:34,  8.45it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  2%|‚ñè         | 6/300 [00:00<00:33,  8.68it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  2%|‚ñè         | 7/300 [00:00<00:33,  8.85it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  3%|‚ñé         | 8/300 [00:00<00:32,  8.96it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  3%|‚ñé         | 9/300 [00:01<00:31,  9.12it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  3%|‚ñé         | 10/300 [00:01<00:31,  9.15it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  4%|‚ñé         | 11/300 [00:01<00:31,  9.19it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  4%|‚ñç         | 12/300 [00:01<00:31,  9.23it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  4%|‚ñç         | 13/300 [00:01<00:30,  9.28it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  5%|‚ñç         | 14/300 [00:01<00:31,  9.19it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  5%|‚ñå         | 15/300 [00:01<00:31,  8.94it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  5%|‚ñå         | 16/300 [00:01<00:32,  8.68it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  6%|‚ñå         | 17/300 [00:01<00:32,  8.82it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  6%|‚ñå         | 18/300 [00:02<00:31,  8.97it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  6%|‚ñã         | 19/300 [00:02<00:30,  9.08it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  7%|‚ñã         | 20/300 [00:02<00:30,  9.16it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  7%|‚ñã         | 21/300 [00:02<00:30,  9.17it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  7%|‚ñã         | 22/300 [00:02<00:30,  9.12it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  8%|‚ñä         | 23/300 [00:02<00:30,  9.14it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  8%|‚ñä         | 24/300 [00:02<00:30,  9.19it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  8%|‚ñä         | 25/300 [00:02<00:29,  9.21it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  9%|‚ñä         | 26/300 [00:02<00:29,  9.16it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  9%|‚ñâ         | 27/300 [00:03<00:29,  9.14it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  9%|‚ñâ         | 28/300 [00:03<00:29,  9.10it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 10%|‚ñâ         | 29/300 [00:03<00:29,  9.09it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 10%|‚ñà         | 30/300 [00:03<00:29,  9.18it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 10%|‚ñà         | 31/300 [00:03<00:28,  9.28it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 11%|‚ñà         | 32/300 [00:03<00:28,  9.34it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 11%|‚ñà         | 33/300 [00:03<00:28,  9.39it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 11%|‚ñà‚ñè        | 34/300 [00:03<00:28,  9.45it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 12%|‚ñà‚ñè        | 35/300 [00:03<00:28,  9.21it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 12%|‚ñà‚ñè        | 36/300 [00:04<00:28,  9.20it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 12%|‚ñà‚ñè        | 37/300 [00:04<00:28,  9.29it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 13%|‚ñà‚ñé        | 38/300 [00:04<00:28,  9.23it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 13%|‚ñà‚ñé        | 39/300 [00:04<00:28,  9.25it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 13%|‚ñà‚ñé        | 40/300 [00:04<00:27,  9.32it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 14%|‚ñà‚ñé        | 41/300 [00:04<00:27,  9.36it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 14%|‚ñà‚ñç        | 42/300 [00:04<00:27,  9.37it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 14%|‚ñà‚ñç        | 43/300 [00:04<00:27,  9.41it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 15%|‚ñà‚ñç        | 44/300 [00:04<00:26,  9.56it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 15%|‚ñà‚ñå        | 45/300 [00:04<00:26,  9.49it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 15%|‚ñà‚ñå        | 46/300 [00:05<00:26,  9.47it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 16%|‚ñà‚ñå        | 47/300 [00:05<00:26,  9.47it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 16%|‚ñà‚ñå        | 48/300 [00:05<00:26,  9.49it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 16%|‚ñà‚ñã        | 49/300 [00:05<00:26,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 17%|‚ñà‚ñã        | 50/300 [00:05<00:25,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 17%|‚ñà‚ñã        | 51/300 [00:05<00:26,  9.56it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 17%|‚ñà‚ñã        | 52/300 [00:05<00:26,  9.53it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 18%|‚ñà‚ñä        | 53/300 [00:05<00:25,  9.64it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 18%|‚ñà‚ñä        | 54/300 [00:05<00:25,  9.64it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 18%|‚ñà‚ñä        | 55/300 [00:06<00:25,  9.61it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 19%|‚ñà‚ñä        | 56/300 [00:06<00:25,  9.64it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 19%|‚ñà‚ñâ        | 57/300 [00:06<00:25,  9.64it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 19%|‚ñà‚ñâ        | 58/300 [00:06<00:25,  9.61it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 20%|‚ñà‚ñâ        | 59/300 [00:06<00:25,  9.63it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 20%|‚ñà‚ñà        | 60/300 [00:06<00:24,  9.68it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 20%|‚ñà‚ñà        | 61/300 [00:06<00:24,  9.67it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 21%|‚ñà‚ñà        | 62/300 [00:06<00:25,  9.51it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 21%|‚ñà‚ñà        | 63/300 [00:06<00:25,  9.12it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 21%|‚ñà‚ñà‚ñè       | 64/300 [00:06<00:25,  9.12it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 22%|‚ñà‚ñà‚ñè       | 65/300 [00:07<00:25,  9.25it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 22%|‚ñà‚ñà‚ñè       | 66/300 [00:07<00:25,  9.33it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 22%|‚ñà‚ñà‚ñè       | 67/300 [00:07<00:24,  9.39it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 23%|‚ñà‚ñà‚ñé       | 68/300 [00:07<00:24,  9.55it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 23%|‚ñà‚ñà‚ñé       | 69/300 [00:07<00:24,  9.59it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 23%|‚ñà‚ñà‚ñé       | 70/300 [00:07<00:23,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 24%|‚ñà‚ñà‚ñé       | 71/300 [00:07<00:23,  9.67it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 24%|‚ñà‚ñà‚ñç       | 72/300 [00:07<00:23,  9.69it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 24%|‚ñà‚ñà‚ñç       | 73/300 [00:07<00:24,  9.34it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 25%|‚ñà‚ñà‚ñç       | 74/300 [00:08<00:24,  9.31it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 25%|‚ñà‚ñà‚ñå       | 75/300 [00:08<00:24,  9.36it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 25%|‚ñà‚ñà‚ñå       | 76/300 [00:08<00:23,  9.39it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 26%|‚ñà‚ñà‚ñå       | 77/300 [00:08<00:23,  9.42it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 26%|‚ñà‚ñà‚ñå       | 78/300 [00:08<00:23,  9.45it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 26%|‚ñà‚ñà‚ñã       | 79/300 [00:08<00:23,  9.48it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 27%|‚ñà‚ñà‚ñã       | 80/300 [00:08<00:23,  9.51it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 27%|‚ñà‚ñà‚ñã       | 81/300 [00:08<00:22,  9.54it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 27%|‚ñà‚ñà‚ñã       | 82/300 [00:08<00:22,  9.56it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 28%|‚ñà‚ñà‚ñä       | 83/300 [00:08<00:22,  9.57it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 28%|‚ñà‚ñà‚ñä       | 84/300 [00:09<00:22,  9.55it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 28%|‚ñà‚ñà‚ñä       | 85/300 [00:09<00:22,  9.47it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 29%|‚ñà‚ñà‚ñä       | 86/300 [00:09<00:22,  9.48it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:09<00:22,  9.49it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:09<00:22,  9.49it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:09<00:22,  9.52it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 30%|‚ñà‚ñà‚ñà       | 90/300 [00:09<00:21,  9.57it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 30%|‚ñà‚ñà‚ñà       | 91/300 [00:09<00:21,  9.59it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 31%|‚ñà‚ñà‚ñà       | 92/300 [00:09<00:21,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 31%|‚ñà‚ñà‚ñà       | 93/300 [00:10<00:21,  9.67it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:10<00:21,  9.71it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:10<00:21,  9.63it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:10<00:21,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:10<00:21,  9.60it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:10<00:21,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:10<00:21,  9.54it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:10<00:20,  9.56it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:10<00:20,  9.56it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:10<00:20,  9.55it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:11<00:20,  9.39it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:11<00:20,  9.42it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:11<00:20,  9.49it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:11<00:20,  9.51it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:11<00:20,  9.51it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:11<00:20,  9.39it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:11<00:20,  9.42it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:11<00:21,  8.92it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:11<00:20,  9.13it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:12<00:20,  9.26it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:12<00:19,  9.38it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:12<00:19,  9.41it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:12<00:19,  9.48it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:12<00:19,  9.32it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:12<00:20,  9.04it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:12<00:19,  9.19it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:12<00:19,  9.33it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:12<00:19,  9.44it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:13<00:18,  9.53it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:13<00:18,  9.56it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:13<00:18,  9.52it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:13<00:18,  9.50it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:13<00:18,  9.59it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:13<00:18,  9.42it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:13<00:18,  9.47it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:13<00:18,  9.53it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:13<00:17,  9.57it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:13<00:17,  9.56it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:14<00:17,  9.60it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:14<00:17,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:14<00:17,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:14<00:17,  9.59it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:14<00:17,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:14<00:17,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:14<00:17,  9.39it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:14<00:17,  9.44it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:14<00:16,  9.50it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:14<00:16,  9.59it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:15<00:16,  9.61it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:15<00:16,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:15<00:16,  9.57it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:15<00:16,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:15<00:16,  9.60it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:15<00:16,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:15<00:15,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:15<00:15,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:15<00:15,  9.59it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:16<00:15,  9.59it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:16<00:15,  9.63it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:16<00:15,  9.61it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:16<00:15,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:16<00:15,  9.59it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:16<00:15,  9.41it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:16<00:15,  9.32it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:16<00:15,  9.28it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:16<00:15,  9.38it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:16<00:14,  9.52it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:17<00:14,  9.59it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:17<00:14,  9.41it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:17<00:14,  9.49it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:17<00:14,  9.56it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:17<00:14,  9.60it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:17<00:14,  9.63it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:17<00:13,  9.64it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:17<00:13,  9.67it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:17<00:13,  9.73it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:18<00:13,  9.75it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:18<00:13,  9.74it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:18<00:13,  9.68it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:18<00:13,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:18<00:13,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:18<00:13,  9.63it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:18<00:12,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:18<00:12,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:18<00:12,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:18<00:12,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:19<00:12,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:19<00:12,  9.69it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:19<00:12,  9.64it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:19<00:12,  9.63it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:19<00:12,  9.60it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:19<00:12,  9.59it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:19<00:11,  9.61it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:19<00:11,  9.66it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:19<00:11,  9.73it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:19<00:11,  9.74it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:20<00:11,  9.75it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:20<00:11,  9.69it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:20<00:11,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:20<00:11,  9.64it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:20<00:11,  9.66it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:20<00:11,  9.64it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:20<00:10,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:20<00:10,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:20<00:10,  9.64it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:21<00:10,  9.63it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:21<00:10,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:21<00:10,  9.60it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:21<00:10,  9.57it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:21<00:10,  9.31it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:21<00:10,  8.92it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:21<00:10,  8.96it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:21<00:11,  8.51it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:21<00:10,  8.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:22<00:10,  8.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:22<00:10,  8.70it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:22<00:10,  8.74it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:22<00:10,  8.80it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:22<00:10,  8.80it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:22<00:10,  8.77it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:22<00:10,  8.41it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:22<00:10,  8.55it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:22<00:09,  8.83it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:23<00:09,  9.06it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:23<00:08,  9.26it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:23<00:08,  9.42it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:23<00:08,  9.47it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:23<00:08,  9.50it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:23<00:08,  9.54it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:23<00:08,  9.56it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:23<00:08,  9.57it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:23<00:07,  9.51it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:24<00:08,  9.35it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:24<00:07,  9.41it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:24<00:07,  9.35it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:24<00:07,  9.26it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:24<00:07,  9.21it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:24<00:07,  9.28it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:24<00:07,  9.24it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:24<00:07,  9.26it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:24<00:07,  9.29it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:24<00:07,  9.35it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:25<00:06,  9.40it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:25<00:06,  9.41it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:25<00:06,  9.42it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:25<00:06,  9.48it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:25<00:06,  9.51it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:25<00:06,  8.97it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:25<00:06,  9.03it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:25<00:06,  9.02it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:25<00:06,  8.92it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:26<00:06,  8.85it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:26<00:06,  9.01it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:26<00:05,  9.05it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:26<00:05,  9.17it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:26<00:05,  9.23it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:26<00:05,  9.27it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:26<00:05,  9.08it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:26<00:05,  8.98it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:26<00:05,  9.13it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:27<00:05,  9.22it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:27<00:04,  9.32it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:27<00:04,  9.34it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:27<00:04,  9.35it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:27<00:04,  9.34it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:27<00:04,  9.35it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:27<00:04,  9.35it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:27<00:04,  9.37it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:27<00:04,  9.41it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:28<00:04,  9.43it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:28<00:03,  9.45it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:28<00:03,  9.51it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:28<00:03,  9.53it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:28<00:03,  9.55it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:28<00:03,  9.38it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:28<00:03,  9.43it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:28<00:03,  9.46it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:28<00:03,  9.53it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:28<00:03,  9.57it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:29<00:02,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:29<00:02,  9.59it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:29<00:02,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:29<00:02,  9.60it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:29<00:02,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:29<00:02,  9.57it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:29<00:02,  9.56it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:29<00:02,  9.37it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:29<00:02,  9.33it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:30<00:02,  9.37it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:30<00:01,  9.42it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:30<00:01,  9.45it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:30<00:01,  9.40it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:30<00:01,  9.44it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:30<00:01,  9.48it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:30<00:01,  9.53it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:30<00:01,  9.46it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:30<00:01,  9.45it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:30<00:01,  9.27it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:31<00:00,  9.42it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:31<00:00,  9.51it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:31<00:00,  9.47it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:31<00:00,  9.46it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:31<00:00,  9.52it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:31<00:00,  9.18it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:31<00:00,  9.29it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:31<00:00,  8.83it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:31<00:00,  9.07it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:32<00:00,  9.36it/s]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.727\nAccuracy for label positive: 0.805\nAccuracy for label negative: 0.878\nAccuracy for label nuetral: 0.570\n\nClassification Report:\n              precision    recall  f1-score   support\n\n    positive       0.73      0.80      0.76        82\n    negative       0.68      0.88      0.77        90\n     nuetral       0.00      0.00      0.00         0\n\n   micro avg       0.70      0.84      0.77       172\n   macro avg       0.47      0.56      0.51       172\nweighted avg       0.70      0.84      0.77       172\n\n\nConfusion Matrix:\n[[66  5  0]\n [ 2 79  0]\n [ 0  0  0]]\n","output_type":"stream"},{"name":"stderr","text":"\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## UI\n ### This interface allows you to input text and test the performance of the fine-tuned model.","metadata":{}},{"cell_type":"code","source":"from IPython.display import display, clear_output\nimport ipywidgets as widgets\n\nsave_directory = \"/kaggle/working/fine-tuned-llama-3.2-model\"\n\nmodel = AutoModelForCausalLM.from_pretrained(save_directory)\ntokenizer = AutoTokenizer.from_pretrained(save_directory)\npipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n\ndef generate_prompt(text):\n    return f\"\"\"Classify the text into positive, negative, neutral, and return the answer as the corresponding sentiment-analysis disorder label.\ntext: {text}\nlabel: \"\"\".strip()\n\n\ndef classify_text(text):\n    prompt = generate_prompt(text)\n    outputs = pipe(prompt, max_new_tokens=2, do_sample=True, temperature=0.1)\n    result = outputs[0][\"generated_text\"].split(\"label: \")[-1].strip()\n    return result\n\n\ninput_text = widgets.Textarea(\n    value='',\n    placeholder='Enter your text here',\n    layout=widgets.Layout(width='90%', height='100px'),\n    disabled=False\n)\n\n\ninput_text.style = {'description_width': 'initial'}       # Set the background color \ninput_text.add_class('custom-textarea')\n\n\nclassify_button = widgets.Button(\n    description=\"Classify Sentiment\",\n    button_style='success',  \n    layout=widgets.Layout(width='30%')\n)\n\n\nremove_text_button = widgets.Button(\n    description=\"Remove Text\",\n    button_style='danger',  \n    layout=widgets.Layout(width='30%')\n)\n\noutput_area = widgets.Output()\n\n\ndef on_classify_button_click(b):\n    with output_area:\n        clear_output(wait=True)  # previous output\n        sentiment_result = classify_text(input_text.value)\n        print(f\"Sentiment: {sentiment_result}\")\n\n\ndef on_remove_text_button_click(b):\n    input_text.value = \"\"  \n\n\nclassify_button.on_click(on_classify_button_click)\nremove_text_button.on_click(on_remove_text_button_click)\n\n\nbutton_box = widgets.HBox([classify_button, remove_text_button], layout=widgets.Layout(justify_content='center'))\n\ndisplay(input_text)\ndisplay(button_box)\ndisplay(output_area)\n\n# Add custom CSS styling\ndisplay(widgets.HTML(\"\"\"\n<style>\n    .custom-textarea textarea {\n        background-color: #f5deb3 !important; /* Light brown (wheat) */\n        color: #003366;  /* Dark navy text color */\n        border: 2px solid #008000;  /* Green border */\n    }\n</style>\n\"\"\"))","metadata":{"execution":{"iopub.status.busy":"2024-10-14T19:14:05.077216Z","iopub.execute_input":"2024-10-14T19:14:05.077611Z","iopub.status.idle":"2024-10-14T19:14:13.435250Z","shell.execute_reply.started":"2024-10-14T19:14:05.077556Z","shell.execute_reply":"2024-10-14T19:14:13.434409Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"273a5cf0fc0a4774859d1a789c22377c"}},"metadata":{}},{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Textarea(value='', layout=Layout(height='100px', width='90%'), placeholder='Enter your text here', style=Descr‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fda93fcdb4b5465e8c61bc0fb89549ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(Button(button_style='success', description='Classify Sentiment', layout=Layout(width='30%'), st‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95d452536bb14968a16bfacdead82419"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79e487f9c4a7470ba6617ca7c04f52dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HTML(value='\\n<style>\\n    .custom-textarea textarea {\\n        background-color: #f5deb3 !important; /* Light‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95ce1d836a00453cba64ac4a64c9aaee"}},"metadata":{}}]},{"cell_type":"markdown","source":"###  <div style=\"box-shadow: rgba(240, 46, 170, 0.4) -5px 5px inset, rgba(240, 46, 170, 0.3) -10px 10px inset, rgba(240, 46, 170, 0.2) -15px 15px inset, rgba(240, 46, 170, 0.1) -20px 20px inset, rgba(240, 46, 170, 0.05) -25px 25px inset; padding:20px; font-size:30px; font-family: consolas; display:fill; border-radius:15px; color: rgba(240, 46, 170, 0.7)\"> <b> ‡ºº‚Å† ‚Å†„Å§‚Å† ‚Å†‚óï‚Å†‚Äø‚Å†‚óï‚Å† ‚Å†‡ºΩ‚Å†„Å§ Thank You!</b></div>","metadata":{}}]}